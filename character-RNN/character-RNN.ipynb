{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f700f01",
   "metadata": {},
   "source": [
    "# **Character-RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09573da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe9f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596e13e",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176abeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('names-and-origins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc74397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>normalized_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Abbas</td>\n",
       "      <td>abbas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>abbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>abbott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>Abdi</td>\n",
       "      <td>abdi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>Abel</td>\n",
       "      <td>abel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>English</td>\n",
       "      <td>Abraham</td>\n",
       "      <td>abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>English</td>\n",
       "      <td>Abrahams</td>\n",
       "      <td>abrahams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>English</td>\n",
       "      <td>Abrams</td>\n",
       "      <td>abrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>English</td>\n",
       "      <td>Ackary</td>\n",
       "      <td>ackary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>English</td>\n",
       "      <td>Ackroyd</td>\n",
       "      <td>ackroyd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    origin      name normalized_name\n",
       "0  English     Abbas           abbas\n",
       "1  English     Abbey           abbey\n",
       "2  English    Abbott          abbott\n",
       "3  English      Abdi            abdi\n",
       "4  English      Abel            abel\n",
       "5  English   Abraham         abraham\n",
       "6  English  Abrahams        abrahams\n",
       "7  English    Abrams          abrams\n",
       "8  English    Ackary          ackary\n",
       "9  English   Ackroyd         ackroyd"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b9a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20074"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd6c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['origin'] = df['origin'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef47d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['origin_code'] = df['origin'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2552cf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['origin'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f83c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>origin_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Abbas</td>\n",
       "      <td>abbas</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>abbey</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>abbott</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>Abdi</td>\n",
       "      <td>abdi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>Abel</td>\n",
       "      <td>abel</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>English</td>\n",
       "      <td>Abraham</td>\n",
       "      <td>abraham</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>English</td>\n",
       "      <td>Abrahams</td>\n",
       "      <td>abrahams</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>English</td>\n",
       "      <td>Abrams</td>\n",
       "      <td>abrams</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>English</td>\n",
       "      <td>Ackary</td>\n",
       "      <td>ackary</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>English</td>\n",
       "      <td>Ackroyd</td>\n",
       "      <td>ackroyd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    origin      name normalized_name  origin_code\n",
       "0  English     Abbas           abbas            4\n",
       "1  English     Abbey           abbey            4\n",
       "2  English    Abbott          abbott            4\n",
       "3  English      Abdi            abdi            4\n",
       "4  English      Abel            abel            4\n",
       "5  English   Abraham         abraham            4\n",
       "6  English  Abrahams        abrahams            4\n",
       "7  English    Abrams          abrams            4\n",
       "8  English    Ackary          ackary            4\n",
       "9  English   Ackroyd         ackroyd            4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16274c",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255e59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, num_tokens=26):\n",
    "        self.num_tokens = num_tokens\n",
    "        self.tokens = list(string.ascii_lowercase)\n",
    "        self.token_to_index = {ch:i for i,ch in enumerate(self.tokens)}\n",
    "        self.index_to_token = {i:ch for i,ch in enumerate(self.tokens)}\n",
    "        \n",
    "    def tokenize(self, x):\n",
    "        one_hot = torch.zeros(self.num_tokens, dtype=torch.long)\n",
    "        if x not in self.tokens:\n",
    "            raise Exception(\"unknown token\")\n",
    "        else:\n",
    "            idx = self.token_to_index[x]\n",
    "        one_hot[idx] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def get_char(self,x):\n",
    "        idx = torch.argmax(x).item()\n",
    "        return self.index_to_token[idx]\n",
    "    \n",
    "    def tokenize_name(self, name):\n",
    "        vector = torch.zeros(size=(len(name), self.num_tokens))\n",
    "        for i,ch in enumerate(name):\n",
    "            vector[i] = self.tokenize(ch)\n",
    "            \n",
    "        return vector\n",
    "    \n",
    "    def get_name(self,vector):\n",
    "        name = ''\n",
    "        for i in range(vector.size(0)):\n",
    "            if torch.sum(vector[i]).item() == 1:\n",
    "                name += self.get_char(vector[i])\n",
    "            \n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfff3cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 26])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = Tokenizer()\n",
    "tk.tokenize_name('shreyas').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d2394",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb6713",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e9b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset:\n",
    "    \n",
    "    def __init__(self, df, max_length=19, is_test = False):\n",
    "        \n",
    "        self.is_test = is_test\n",
    "        self.df = df\n",
    "        \n",
    "#         self.df['origin'] = self.df['origin'].astype('category')\n",
    "#         self.df['origin_code'] = self.df['origin'].cat.codes\n",
    "        \n",
    "        self.names = list(self.df['normalized_name'])\n",
    "        self.origins = list(self.df['origin'])\n",
    "        self.categories = {i:origin for i, origin in enumerate(self.df['origin'].cat.categories)}\n",
    "        self.labels = list(self.df['origin_code'])\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.tk = Tokenizer()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        name = self.tk.tokenize_name(self.names[idx])\n",
    "        pad_zeros = torch.zeros(size=(self.max_length-name.size(0), self.tk.num_tokens))\n",
    "        \n",
    "        padded = torch.concat([name,pad_zeros])\n",
    "        \n",
    "        if self.is_test is False:\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return (padded, label)\n",
    "        \n",
    "        return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82da02",
   "metadata": {},
   "source": [
    "### Shuffle-Split Dataframe into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c529be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.2, shuffle=True, random_state = 1357)\n",
    "type(train), type(val)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c635408a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16059, 4), (4015, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81cc8968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(map(len, df['normalized_name'].values))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f89fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NamesDataset(train)\n",
    "val_ds = NamesDataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "850cc442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16059, 4015)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "675068c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19, 26]), torch.Size([19, 26]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape, val_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cd0447",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a624a",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "![RNN diagram](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/640px-Recurrent_neural_network_unfold.svg.png)\n",
    "\n",
    "[Image src: By fdeloche - Own work, CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=60109157)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8dd84",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "- In this we'll be using a many-to-one RNN. Many inputs i.e. the sequence of characters (name) and the output (origin)\n",
    "- The longest name in the list is 19 characters long.\n",
    "- Total number of tokens/characters are 26 - lowercase alphabets\n",
    "- Each token has been one-hot encoded in the shape (1,26)\n",
    "- Each name is in the shape (19, 26) after padding with zeros.\n",
    "\n",
    "[RNN pytorch docs](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
    "\n",
    "For the RNN:\n",
    "\n",
    "- N = batch_size\n",
    "- L = sequence length\n",
    "- D = 1 (unidirectional)\n",
    "- Hin = input_size\n",
    "- Hout = hidden_size\n",
    "\n",
    "Shapes:\n",
    "\n",
    "- input: `(N,L,Hin)` when batch_first=True\n",
    "- hidden:  `(Dâˆ—num_layers,N,Hout)` -- initialized to zeros automatically by torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26a3513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=26, seq_len=19, hidden_size=64, num_classes=18):\n",
    "        \n",
    "        super(RNNModel, self).__init__()\n",
    "        self.input_size = input_size \n",
    "        self.sequence_length = seq_len \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = 1\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.RNN(self.input_size, self.hidden_size, self.num_layers ,batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size * self.sequence_length, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # X: shape: batch x seq_len x input_size\n",
    "        batch_size = x.size(0)\n",
    "        x, h_out = self.rnn(x)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70692312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0639,  0.1338, -0.0672, -0.0165,  0.0578,  0.1744,  0.0541,  0.0883,\n",
       "         -0.1580,  0.0591, -0.1514,  0.0150,  0.0386,  0.2637,  0.1453,  0.1607,\n",
       "         -0.0078,  0.0740]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RNNModel()\n",
    "x = torch.rand((1,19,26))\n",
    "x = m(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71af6ef",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9755a23",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6832d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c134e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 63)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432ea1d",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08218d6b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e87bbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, loaders, config):\n",
    "        self.model = model\n",
    "        self.train_loader, self.val_loader = loaders\n",
    "        self.config = config\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.config['lr'])\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        \n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        \n",
    "        for x,y in self.train_loader:\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            preds = self.model(x)\n",
    "            \n",
    "            loss = self.loss_fn(preds, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            pred_labels = torch.argmax(preds,dim=1)\n",
    "            running_acc += accuracy_score(pred_labels, y)\n",
    "        \n",
    "        train_loss = running_loss / len(self.train_loader)\n",
    "        train_acc = running_acc / len(self.train_loader)\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.train_accs.append(train_acc)\n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def valid_one_epoch(self):\n",
    "        \n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        \n",
    "        for x,y in self.val_loader:\n",
    "            \n",
    "            preds = self.model(x)\n",
    "            loss = self.loss_fn(preds, y)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            pred_labels = torch.argmax(preds,dim=1)\n",
    "            running_acc += accuracy_score(pred_labels, y)\n",
    "            \n",
    "        val_loss = running_loss / len(self.val_loader)\n",
    "        val_acc = running_acc / len(self.val_loader)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_accs.append(val_acc)\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            \n",
    "            self.model.train()\n",
    "\n",
    "            self.train_one_epoch()\n",
    "            \n",
    "            self.model.eval()\n",
    "            \n",
    "            self.valid_one_epoch()\n",
    "            \n",
    "        \n",
    "            print(f\"\\n\\n{'-'*7}EPOCH: {epoch+1}/{self.config['epochs']}{'-'*7}\")\n",
    "            print(f\"Train Loss: {self.train_losses[-1]} | Validation Loss: {self.val_losses[-1]}\")\n",
    "            print(f\"Train Accuracy: {self.train_accs[-1]} | Validation Accuracy: {self.val_accs[-1]}\")\n",
    "            \n",
    "            \n",
    "    \n",
    "    def predict(self, name):\n",
    "        \n",
    "        self.tk = Tokenizer()\n",
    "        name = self.tk.tokenize_name(name)\n",
    "        pad_zeros = torch.zeros(size=(19-name.size(0), self.tk.num_tokens))\n",
    "        \n",
    "        padded = torch.concat([name,pad_zeros])\n",
    "        x = torch.unsqueeze(padded, dim=0)\n",
    "        \n",
    "        x = model(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cca536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 20\n",
    "}\n",
    "\n",
    "model = RNNModel()\n",
    "trainer = Trainer(model, (train_loader, val_loader), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deb3fcc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------EPOCH: 1/20-------\n",
      "Train Loss: 1.536788992197865 | Validation Loss: 1.2916508354837932\n",
      "Train Accuracy: 0.555899284219056 | Validation Accuracy: 0.6277123438027693\n",
      "\n",
      "\n",
      "-------EPOCH: 2/20-------\n",
      "Train Loss: 1.1643616989314318 | Validation Loss: 1.1008577545483906\n",
      "Train Accuracy: 0.6548424944290634 | Validation Accuracy: 0.6617116261398177\n",
      "\n",
      "\n",
      "-------EPOCH: 3/20-------\n",
      "Train Loss: 1.0384506870550938 | Validation Loss: 1.024940640207321\n",
      "Train Accuracy: 0.6868036329259234 | Validation Accuracy: 0.6855211499493415\n",
      "\n",
      "\n",
      "-------EPOCH: 4/20-------\n",
      "Train Loss: 0.9646633573737278 | Validation Loss: 0.9646554021608262\n",
      "Train Accuracy: 0.7026670858937132 | Validation Accuracy: 0.704122340425532\n",
      "\n",
      "\n",
      "-------EPOCH: 5/20-------\n",
      "Train Loss: 0.9137719259319077 | Validation Loss: 0.9396944216319493\n",
      "Train Accuracy: 0.7171662924572895 | Validation Accuracy: 0.7095786896318812\n",
      "\n",
      "\n",
      "-------EPOCH: 6/20-------\n",
      "Train Loss: 0.8807445021264582 | Validation Loss: 0.9204899933603075\n",
      "Train Accuracy: 0.725331723951651 | Validation Accuracy: 0.7141590678824721\n",
      "\n",
      "\n",
      "-------EPOCH: 7/20-------\n",
      "Train Loss: 0.8556953186532891 | Validation Loss: 0.8998104551481823\n",
      "Train Accuracy: 0.7294191876561551 | Validation Accuracy: 0.7131406197230665\n",
      "\n",
      "\n",
      "-------EPOCH: 8/20-------\n",
      "Train Loss: 0.8312071105873442 | Validation Loss: 0.8834229868555826\n",
      "Train Accuracy: 0.7380151006144912 | Validation Accuracy: 0.7269186930091185\n",
      "\n",
      "\n",
      "-------EPOCH: 9/20-------\n",
      "Train Loss: 0.8124381128060391 | Validation Loss: 0.8630964159965515\n",
      "Train Accuracy: 0.7408322219596192 | Validation Accuracy: 0.7301851148260723\n",
      "\n",
      "\n",
      "-------EPOCH: 10/20-------\n",
      "Train Loss: 0.7988773316026209 | Validation Loss: 0.8486463285627819\n",
      "Train Accuracy: 0.743996471740158 | Validation Accuracy: 0.7367707277946639\n",
      "\n",
      "\n",
      "-------EPOCH: 11/20-------\n",
      "Train Loss: 0.7771215119447367 | Validation Loss: 0.8467274592036292\n",
      "Train Accuracy: 0.7549220490917685 | Validation Accuracy: 0.7321481340763256\n",
      "\n",
      "\n",
      "-------EPOCH: 12/20-------\n",
      "Train Loss: 0.7588412685698247 | Validation Loss: 0.8169082261267162\n",
      "Train Accuracy: 0.7587088088324667 | Validation Accuracy: 0.7511767561634584\n",
      "\n",
      "\n",
      "-------EPOCH: 13/20-------\n",
      "Train Loss: 0.7366865533756545 | Validation Loss: 0.8023101649587117\n",
      "Train Accuracy: 0.7666041343102168 | Validation Accuracy: 0.7472559945964201\n",
      "\n",
      "\n",
      "-------EPOCH: 14/20-------\n",
      "Train Loss: 0.7209324974462805 | Validation Loss: 0.7892000381908719\n",
      "Train Accuracy: 0.7694835066513607 | Validation Accuracy: 0.7532980834177642\n",
      "\n",
      "\n",
      "-------EPOCH: 15/20-------\n",
      "Train Loss: 0.7007615098440315 | Validation Loss: 0.7865259760902041\n",
      "Train Accuracy: 0.7783125970693497 | Validation Accuracy: 0.7554827338736914\n",
      "\n",
      "\n",
      "-------EPOCH: 16/20-------\n",
      "Train Loss: 0.6815174383471212 | Validation Loss: 0.7722527687511747\n",
      "Train Accuracy: 0.7867217570396381 | Validation Accuracy: 0.7642793819655521\n",
      "\n",
      "\n",
      "-------EPOCH: 17/20-------\n",
      "Train Loss: 0.6621131729557219 | Validation Loss: 0.7460887290182567\n",
      "Train Accuracy: 0.7890767438719698 | Validation Accuracy: 0.7742211246200608\n",
      "\n",
      "\n",
      "-------EPOCH: 18/20-------\n",
      "Train Loss: 0.641874843978312 | Validation Loss: 0.739996445084375\n",
      "Train Accuracy: 0.7959243534337228 | Validation Accuracy: 0.7822262326916581\n",
      "\n",
      "\n",
      "-------EPOCH: 19/20-------\n",
      "Train Loss: 0.6312092832360134 | Validation Loss: 0.7418906400128017\n",
      "Train Accuracy: 0.7996129887230737 | Validation Accuracy: 0.7784585021952044\n",
      "\n",
      "\n",
      "-------EPOCH: 20/20-------\n",
      "Train Loss: 0.6144024833027585 | Validation Loss: 0.7160941234656742\n",
      "Train Accuracy: 0.8038513319602945 | Validation Accuracy: 0.7846588990206012\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e325e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yu : Korean\n",
      "nobita : Japanese\n",
      "adam : English\n"
     ]
    }
   ],
   "source": [
    "name = 'yu'\n",
    "pred = torch.argmax(trainer.predict(name), dim=1)\n",
    "labels = list(df['origin'].cat.categories)\n",
    "print(f\"{name} : {labels[pred]}\")\n",
    "\n",
    "name = 'nobita'\n",
    "pred = torch.argmax(trainer.predict(name), dim=1)\n",
    "labels = list(df['origin'].cat.categories)\n",
    "print(f\"{name} : {labels[pred]}\")\n",
    "\n",
    "name = 'adam'\n",
    "pred = torch.argmax(trainer.predict(name), dim=1)\n",
    "labels = list(df['origin'].cat.categories)\n",
    "print(f\"{name} : {labels[pred]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
